{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SILIA\n",
    "import numpy as np\n",
    "from scipy.signal import square\n",
    "import plotly.express as px #I like using plotly for my graphs, but feel free to use matplotlib or any other library\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "from matplotlib import animation, rc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will go over using SILIA for higher dimensional data. Please see the basic tutorial prior to moving on to this one. If you haven't done so already, all depencencies can be installed using pip, we use plotly and pillow which do not generally come pre-installed. In this case, we will simulate fluoresence microscopy data where the sample fluoresces at 100Hz and the microscope takes images on a 100x100 pixel array. The fluoresence is concentrated in a few randomly placed circles with a signal peak of 2 while the background has a peak of 0.2, resulting in a 10:1 ratio for the concentration of the fluorescent molecule between the circles and the background. We will see if the Lock-in can recover this result despite significant noise. \n",
    "\n",
    "First, let us create our time axis and note down our frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = 5000 #Hz\n",
    "sim_time = 1 #second\n",
    "#Time axis\n",
    "time = np.arange(0, sim_time, 1/sampling_rate)\n",
    "#Frequency (Hz)\n",
    "freq = 100\n",
    "#Number of rows in each frame\n",
    "rows = 100\n",
    "#Number of columns in each frame\n",
    "cols = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's simulate our 100Hz reference signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "references = [{'time' : time, 'signal' : square(2 * np.pi * freq * time)}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's generate our data. Our signal is represented by a dictionary which contains the time axis under the key, 'time'. The actual signal data is under the key 'signal' and is a 3D array in this case. The first index of this array represents the time axis, i.e. signal['signal'][i] would refer to the image frame at the i'th timestep. The next two indices represent the coordinates of an individual pixel. i.e. signal['signal'][:, x, y] is a 1D array which represents the signal value over time for a single pixel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inside(centers, radii, point):\n",
    "    \"\"\"\n",
    "    Returns whether or not the point, given by a list [x, y], \n",
    "    is inside one of the circles with center given by centers[i]\n",
    "    and radius given by radii[i] for some index, i. \n",
    "    \"\"\"\n",
    "    for i, center in enumerate(centers):\n",
    "        dist_from_center = np.sqrt((point[0] - center[0])**2 + (point[1] - center[1])**2)\n",
    "        if dist_from_center < radii[i]:\n",
    "            return True\n",
    "    return False\n",
    "#Adding the time axis to our data\n",
    "dat = {'time' : time}\n",
    "\n",
    "#Creating an empty pixel array for each timestamp\n",
    "clean_signal = np.zeros((len(time), rows,cols))\n",
    "\n",
    "#Defining the location and sizes of each circle. \n",
    "centers = np.random.randint(100, size = (20, 2))\n",
    "radii = np.random.normal(5, 1, 20)\n",
    "\n",
    "#Populating the empty signal array\n",
    "for x in tqdm(range(rows), position = 0, leave = True):\n",
    "    for y in range(cols):      \n",
    "        if inside(centers, radii, [x, y]):\n",
    "            clean_signal[:, x, y] = square(2 * np.pi * 100 * time) + 1\n",
    "        else:\n",
    "            clean_signal[:, x, y] = 0.1 * square(2 * np.pi * 100 * time) + 0.1\n",
    "dat['signal'] = clean_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's visualize a slowed down version of our generated signal, this might take a couple minutes. The animation can be finicky at times, if it doesn't work just skip this step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%matplotlib inline\n",
    "\n",
    "#Scale to slow down animation by\n",
    "slow_down = 25\n",
    "# First set up the figure, the axis, and the plot element we want to animate\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlim(( 0, rows))\n",
    "ax.set_ylim((0, cols))\n",
    "im = ax.imshow(np.zeros((rows, cols)))\n",
    "\n",
    "# initialization function: plot the background of each frame\n",
    "def init():\n",
    "    im.set_data(np.zeros((rows, cols)))\n",
    "    return (im,)\n",
    "\n",
    "# animation function. This is called sequentially\n",
    "def animate(i):\n",
    "    ax.imshow(clean_signal[i])\n",
    "    im.set_data(clean_signal[i])\n",
    "    \n",
    "    return (im,)\n",
    "# call the animator.\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=150, interval=1000/sampling_rate * slow_down, blit = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " If it doesn't work, try replacing 'jshtml' on the line below with 'html5'. To use 'html5' make sure you have installed FFmpeg. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc('animation', html='jshtml') #Maybe replace 'jshtml' with 'html5'\n",
    "anim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the animation did not work, we can just visualize the two fluorescent and non-fluorescent frames below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots()\n",
    "#Displaying when the sample is fluorescing\n",
    "ax1.set_title(\"Fluorescing\")\n",
    "ax1.imshow(clean_signal[0])\n",
    "\n",
    "fig12, ax2 = plt.subplots()\n",
    "#Displaying when the sample is not fluorescing\n",
    "ax2.set_title(\"Not Fluorescing\")\n",
    "ax2.imshow(clean_signal[sampling_rate//(2 * freq), :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's add some Gaussian noise to our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0\n",
    "standard_deviation = 1\n",
    "noisy_signal = np.random.normal(mean, standard_deviation, clean_signal.shape) + clean_signal\n",
    "dat['signal'] = noisy_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing our Noisy signal the same way as above, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%matplotlib inline\n",
    "\n",
    "#Scale to slow down animation by\n",
    "slow_down = 25\n",
    "# First set up the figure, the axis, and the plot element we want to animate\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlim(( 0, rows))\n",
    "ax.set_ylim((0, cols))\n",
    "im = ax.imshow(np.zeros((rows, cols)))\n",
    "\n",
    "# initialization function: plot the background of each frame\n",
    "def init():\n",
    "    im.set_data(np.zeros((rows, cols)))\n",
    "    return (im,)\n",
    "\n",
    "# animation function. This is called sequentially\n",
    "def animate(i):\n",
    "    ax.imshow(noisy_signal[i])\n",
    "    im.set_data(noisy_signal[i])\n",
    "    \n",
    "    return (im,)\n",
    "# call the animator.\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=150, interval=1000/sampling_rate * slow_down, blit = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc('animation', html='jshtml') #Maybe replace 'jshtml' with 'html5'\n",
    "anim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if the animation doesn't work, we can visualize it frame by frame, like before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots()\n",
    "#Displaying when the sample is fluorescing\n",
    "ax1.set_title(\"Fluorescing\")\n",
    "ax1.imshow(noisy_signal[0])\n",
    "\n",
    "fig12, ax2 = plt.subplots()\n",
    "#Displaying when the sample is not fluorescing\n",
    "ax2.set_title(\"Not Fluorescing\")\n",
    "ax2.imshow(noisy_signal[sampling_rate//(2 * freq), :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, with all this noise, it is extremely difficult to figure out the relative concentrations of the relative fluoresence between the circles and the background. The lock-in is necessary to extract the signal. Now, we can create our lock-in amplifier and lock into our signal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIA = SILIA.Amplifier(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that our input signal array is now 3D. SILIA is designed to handle n-dimsnsional input data as long as the first axis is the time axis. To get errorbars, we choose a split for our data into 4 windows where each window contains a third of the data. There is an error overestimation if there is no overlap between the windows and a significant number of windows, and vice versa if there is significant overlap between the windows and a fewer number of windows, so the window size and number of windows should be well balanced. This step might take a few minutes since we are running the lock-in repeatedly on large amounts of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = LIA.amplify(references, dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's visualize our output magnitudes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mags = np.asarray(out['reference 1']['magnitudes'])\n",
    "plt.imshow(mags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lock-in reduced noise! Now, let's check if we can correctly derive the fluoresence ratio from our result. By averaging the output magnitudes from inside the circles vs outside. Note that the exact magnitudes of the output might be scaled since the lock-in only extracts the primary Fourier component of the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratio(image_array):\n",
    "    background_sum = 0\n",
    "    num_background_points = 0\n",
    "    circle_sum = 0\n",
    "    num_circle_points = 0\n",
    "    for x in range(len(image_array)):\n",
    "        for y in range(len(image_array[0])):\n",
    "            val = mags[x][y]\n",
    "            if inside(centers, radii, [x, y]):\n",
    "                num_circle_points += 1\n",
    "                circle_sum = circle_sum + val\n",
    "            else:\n",
    "                num_background_points += 1\n",
    "                background_sum = background_sum + val\n",
    "    circle_avg = circle_sum/num_circle_points\n",
    "    background_avg = background_sum/num_background_points\n",
    "    return circle_avg/background_avg\n",
    "\n",
    "ratio = get_ratio(mags)\n",
    "print(\"The fluoresence ratio between the foreground and background after lock-in is, \" + str(ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is near our expected result of 10:1!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
